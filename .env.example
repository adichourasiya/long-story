# Environment Configuration for Novel Memory Architecture

# Azure OpenAI Configuration (Required)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1

# Optional: Fallback deployment
AZURE_OPENAI_FALLBACK_DEPLOYMENT=gpt-4o

# Model Configuration
AZURE_OPENAI_MAX_TOKENS=8192
AZURE_OPENAI_TEMPERATURE=0.7
AZURE_OPENAI_TOP_P=0.95

# ChromaDB Configuration
CHROMA_DB_PATH=./chroma_db
CHROMA_COLLECTION_PREFIX=novel_memory

# Embedding Model Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
# Alternative: all-mpnet-base-v2 (higher quality, slower)

# Story Storage Configuration
STORY_BASE_PATH=./story
BACKUP_PATH=./backups

# Memory Management Configuration
MAX_CONTEXT_TOKENS=32000
RESERVED_OUTPUT_TOKENS=2000
SUMMARY_TRIGGER_TOKENS=4000
KEEP_RECENT_MESSAGES=20

# Performance Settings
CACHE_SIZE=1000
BATCH_SIZE=50
MAX_CONCURRENT_REQUESTS=5

# Development Settings
DEBUG=false
LOG_LEVEL=INFO
ENABLE_ANALYTICS=true
ANALYTICS_LOG_FILE=azure_openai_usage.jsonl

# LangSmith Configuration (Optional)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=novel-memory-architecture